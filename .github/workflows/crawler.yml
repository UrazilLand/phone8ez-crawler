name: Daily SmartChoice Crawler

on:
  schedule:
    # KST 자정 (15:00 UTC)에 매일 실행
    - cron: '0 15 * * *'
  # 수동으로 워크플로우를 실행할 수 있도록 설정
  workflow_dispatch:

jobs:
  crawl-and-commit:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create data directory
      run: mkdir -p data
      
    - name: Run crawler
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: python main.py
      
    - name: Upload data files
      uses: actions/upload-artifact@v4
      with:
        name: phone-support-data
        path: data/
        retention-days: 30
        
    - name: Commit and push data files
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # data 폴더의 파일들이 있는지 확인
        if [ -d "data" ] && [ "$(ls -A data)" ]; then
          echo "데이터 파일이 발견되었습니다. 커밋을 진행합니다."
          git add data/
          git diff --quiet && git diff --staged --quiet || git commit -m "📱 스마트초이스 크롤링 데이터 업데이트 - $(date '+%Y-%m-%d %H:%M:%S')"
          git push
          echo "데이터 파일 커밋 및 푸시 완료"
        else
          echo "데이터 파일이 없습니다. 크롤링이 실패했거나 파일이 생성되지 않았습니다."
          exit 1
        fi 